The first step of the pipeline involves cleaning the raw fastq files using Stacks, using process radtags which will demultiplex the illumina files, remove adapters and read the enzime overhang.

```
# For this we need:
# 1. barcodes. I have them under the /Papers/Stygocapitella_PeerJ/info. They are called "barcodes_lane01.tsv", and "barcodes_lane02.tsv"
# 2. the illumina raw files. "1-Jose-lib-18X-2XP-L1_S18_L005_R1_001.fastq.gz" is the forward library for lane 1, "1-Jose-lib-18X-2XP-L1_S18_L005_R2_001.fastq.gz" is the reverse for lane 1. "2-L2-18X-Amp-2XP_S19_L006_R1_001.fastq.gz" is the forward for lane 02, and "2-L2-18X-Amp-2XP_S19_L006_R12_001.fastq.gz" is the reverse for lane 02.

#stacks version 4.1
process_radtags -i gzfastq -1 $lane01_Forward -2 $lane01_Reverse -b barcodes_lane01.tsv -o $output_folder --renz_1 pstI --renz_2 mseI -q -r -c
process_radtags -i gzfastq -1 $lane02_Forward -2 $lane02_Reverse -b barcodes_lane02.tsv -o $output_folder --renz_1 pstI --renz_2 mseI -q -r -c

# Notice, I have uploaded the output from process_radtags on ENA:
# https://www.ebi.ac.uk/ena/browser/view/PRJEB40223
```

The second step consists in optimizing Stacks on the whole data, following [Paris et al 2017](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12775)

```
# For this we need:
# 1. to specify the popmap. See popmap_complete.tsv under the folder "info". Notice that I reduced the number of samples to two-per-population. So it'd be more efficient in running the optimization. I will call this file as "popmap".
# 2. We need to specify the directory with the data generated by process_radtags. I will call this "reads_dir"
# 3. We need to specify an output directory. I will call this "out_dir".
# 4. I will save a log of the run. I will call this "logfile":

denovo_map.pl

logfile=$out_dir/denovo_map.oe

for i in $(seq 1 7); do;
mkdir run_M${i}; cd $run_M${i};
denovo_map.pl --samples $reads_dir -O $popmap -o $out_dir -M $M -n $M -m 3 -T 4 &> $logfile;
cd ..;
done

# Code explained:
# we do a loop in the sequence of numbers between 1-7 (1 2 3 4 5 6 7)
# for each of these numbers our computer will create a folder and move into it. Say for 1, our computer will create a folder called run_M1, and move in there.
# Then, inside this folder, the denovo_map.pl script will run the whole Stacks script. For the specific flags, please consult the Stacks website.
# Then we move back up so we can re-start a new loop at the right place
```
Conclusion: we chose -M 3 -n 3 as the best approach (see Paris et al for insights)

Now, I found that the dataset has too much missing data. What I did was run the dataset on a population by population level to understand how to remove specimens. I did this for each population in the dataset (see "Site" on supplementary Table 2.
For example, for the population Ardtoe, in Stygocapitella I did:
```
denovo_map.pl --samples $reads_dir -O $popmap_onlyArdToe_Stygocapitella -o $out_dir -M 3 -n 3 -m 3 -T 4 &> $logfile

# Now, to see the % of missing individuals, I used vcftools in the following way, analysing the populations.snp.vcf
vcftools --missing-indv populations.snp.vcf
cat out.imiss
```

On the final column of out.imiss we can see the % of missing data. I noted down samples with >45% missing data. After doing this for all populations for all three species, I generated a final dataset by using the "clean population map", which is in the folder info.

```
denovo_map.pl --samples $reads_dir -O $popmap_cleaned -o $out_dir -M 3 -n 3 -m 3 -T 4 &> $logfile

# And I cleaned the final dataset, by using the "populations" module. The final of stacks. I asked it to generate a vcf file, with the following cut-offs: -r 0.25, -p 4.
populations -P $out_dir -M $popmap_complete -t 4 --vcf --fasta-samples --fasta-loci -O $out_dir/r_25_p4 -r 0.25 -p 5 &> $out_dir/r_25_p4/logfile.oe
```
